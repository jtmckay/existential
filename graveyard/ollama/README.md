# RIP replacing all AI use with LocalAI

# Ollama

### Pick your LLM

In the `ollama_entrypoint.sh` uncomment the LLM you want to preload.

See GPU install under [Proxmox](../../hosting/proxmox/README.md#gpu)
