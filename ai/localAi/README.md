# LocalAI

- Source: [https://github.com/mudler/LocalAI](https://github.com/mudler/LocalAI)
- License: [MIT](https://opensource.org/licenses/MIT)
- Alternatives: Ollama, LM Studio, GPT4All, Chatbot UI

## Features

- **OpenAI API Compatible**: Drop-in replacement for OpenAI's REST API endpoints (chat, completions, embeddings, transcription).
- **Fully Local & Private**: Runs all AI models locally; no data leaves your machine.
- **Multi-Model Support**: Supports LLaMA, Mistral, RWKV, and more with GGUF and GPTQ models.
- **Lightweight Deployment**: Single binary or Docker container, minimal config.
- **Hardware Flexible**: CPU and GPU support across Linux, macOS, and Windows.
- **Embeddings & RAG Support**: Generate and serve embeddings for retrieval-augmented generation.
- **Multimodal Capabilities**: Speech-to-text and text-to-speech integration; early support for vision models.
- **Extensible & Integratable**: Works seamlessly with existing client libraries and frontends like LibreChat.
